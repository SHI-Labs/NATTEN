#!/bin/bash
# Copyright (c) 2022 - 2026 Ali Hassani.
#
# Parallel test runner for NATTEN unit tests
# Runs tests across multiple GPUs with dynamic load balancing
#
# Generated by Claude Code
#
# Usage: run_tests_parallel.sh [NUM_GPUS] [WORKERS]
#   NUM_GPUS: Number of GPUs to distribute tests across (default: -1 [auto detect])
#   WORKERS: Number of concurrent test workers (default: NATTEN_N_WORKERS, or NUM_GPUS, if set,
#     otherwise nproc/4)

set -e

# Check for required commands
if ! command -v parallel &> /dev/null; then
    echo "Error: GNU parallel is not installed. Please install it first."
    exit 1
fi

if ! command -v nproc &> /dev/null; then
    echo "Error: nproc command not found. Please ensure coreutils is installed."
    exit 1
fi

# Parse NUM_GPUS argument
NUM_GPUS=${1:--1}

# Auto-detect GPUs if NUM_GPUS < 0
if [ ${NUM_GPUS} -lt 0 ]; then
    if command -v nvidia-smi &> /dev/null; then
        NUM_GPUS=$(nvidia-smi --query-gpu=index --format=csv,noheader | wc -l)
        echo "Auto-detected ${NUM_GPUS} GPUs"
    else
        NUM_GPUS=0
        echo "No GPUs detected (nvidia-smi not found), setting NUM_GPUS=0"
    fi
fi

# Validate requested NUM_GPUS doesn't exceed available
if [ ${NUM_GPUS} -gt 0 ]; then
    if command -v nvidia-smi &> /dev/null; then
        AVAILABLE_GPUS=$(nvidia-smi --query-gpu=index --format=csv,noheader | wc -l)
        if [ ${NUM_GPUS} -gt ${AVAILABLE_GPUS} ]; then
            echo "Error: Requested ${NUM_GPUS} GPUs but only ${AVAILABLE_GPUS} available"
            exit 1
        fi
    else
        echo "Error: Requested ${NUM_GPUS} GPUs but nvidia-smi not found"
        exit 1
    fi
fi

# Handle WORKERS - priority: argument > NATTEN_N_WORKERS > (NUM_GPUS if > 0, otherwise nproc/4)
if [ -n "$2" ]; then
    WORKERS=$2
elif [ -n "${NATTEN_N_WORKERS}" ]; then
    WORKERS=${NATTEN_N_WORKERS}
    echo "Using WORKERS=${WORKERS} from NATTEN_N_WORKERS"
elif [ ${NUM_GPUS} -gt 0 ]; then
    # Default to one worker per GPU when using GPUs
    WORKERS=${NUM_GPUS}
    echo "Using WORKERS=${WORKERS} (default: same as NUM_GPUS)"
else
    # No GPUs, default to nproc/4
    WORKERS=$(( $(nproc) / 4 ))
    # Ensure at least 1 worker
    if [ ${WORKERS} -lt 1 ]; then
        WORKERS=1
    fi
    echo "Using WORKERS=${WORKERS} (default: nproc/4)"
fi

# Validate WORKERS is positive
if [ ${WORKERS} -lt 1 ]; then
    echo "Error: WORKERS must be >= 1 (got: ${WORKERS})"
    exit 1
fi

# Ensure WORKERS >= NUM_GPUS (need at least one worker per GPU)
if [ ${NUM_GPUS} -gt 0 ] && [ ${WORKERS} -lt ${NUM_GPUS} ]; then
    echo "Overriding WORKERS from ${WORKERS} to ${NUM_GPUS} (minimum: one worker per GPU)"
    WORKERS=${NUM_GPUS}
fi

# Guard against too many workers
if [ ${WORKERS} -gt 16 ]; then
    echo "Warning: Using ${WORKERS} workers for testing may be excessive."
    read -p "Are you sure you want to continue? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo "Aborted."
        exit 1
    fi
fi

# Validate NUM_GPUS
if [ ${NUM_GPUS} -gt 0 ]; then
    if command -v nvidia-smi &> /dev/null; then
        AVAILABLE_GPUS=$(nvidia-smi --query-gpu=index --format=csv,noheader | wc -l)
        if [ ${NUM_GPUS} -gt ${AVAILABLE_GPUS} ]; then
            echo "Error: Requested ${NUM_GPUS} GPUs but only ${AVAILABLE_GPUS} available"
            exit 1
        fi
    else
        echo "Error: Requested ${NUM_GPUS} GPUs but nvidia-smi not found"
        exit 1
    fi
fi

# Default log level
export NATTEN_LOG_LEVEL="${NATTEN_LOG_LEVEL:-CRITICAL}"

# Always must be set for all tests
export PYTORCH_NO_CUDA_MEMORY_CACHING=1
export CUBLAS_WORKSPACE_CONFIG=":4096:8"

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="${SCRIPT_DIR}/../.."
TEST_DIR="${PROJECT_ROOT}/tests"
LOG_DIR="${PROJECT_ROOT}/test-logs"
PYTEST="${PYTEST:-pytest}"

# Create log directory
mkdir -p "${LOG_DIR}"

# Get all test files
TEST_FILES=($(find "${TEST_DIR}" -name "test_*.py" -type f | sort))
TOTAL_TESTS=${#TEST_FILES[@]}

if [ ${TOTAL_TESTS} -eq 0 ]; then
    echo "No test files found in ${TEST_DIR}"
    exit 1
fi

echo "================================================="
echo "NATTEN Parallel Test Runner"
echo "================================================="
echo "Total tests: ${TOTAL_TESTS}"
echo "Workers: ${WORKERS}"
if [ ${NUM_GPUS} -gt 0 ]; then
    echo "GPUs: ${NUM_GPUS}"
    echo "Max workers per GPU: $(( (WORKERS + NUM_GPUS - 1) / NUM_GPUS ))"
else
    echo "Mode: CPU-only"
fi
echo "Test directory: ${TEST_DIR}"
echo "Log directory: ${LOG_DIR}"
echo "================================================="
echo ""

# Function to run a single test
# This will be called by GNU parallel for each test file
run_single_test() {
    local test_file=$1
    local worker_id=$((PARALLEL_JOBSLOT - 1))
    local test_name=$(basename "${test_file}" .py)

    if [ ${NUM_GPUS} -gt 0 ]; then
        # GPU mode: distribute workers across GPUs using round-robin
        local gpu_id=$(( worker_id % NUM_GPUS ))
        local log_file="${LOG_DIR}/${test_name}_gpu${gpu_id}_worker${worker_id}.log"

        echo "[$(date '+%Y-%m-%d %H:%M:%S')] [GPU ${gpu_id}] [Worker ${worker_id}] Starting: ${test_name}"

        # Run test with specific GPU
        CUDA_VISIBLE_DEVICES=${gpu_id} ${PYTEST} -v -x "${test_file}" > "${log_file}" 2>&1
        local exit_code=$?

        if [ ${exit_code} -eq 0 ]; then
            echo "[$(date '+%Y-%m-%d %H:%M:%S')] [GPU ${gpu_id}] [Worker ${worker_id}] ✓ PASSED: ${test_name}"
        else
            echo "[$(date '+%Y-%m-%d %H:%M:%S')] [GPU ${gpu_id}] [Worker ${worker_id}] ✗ FAILED: ${test_name} (exit code: ${exit_code})"
        fi
    else
        # No GPU distribution: disable CUDA to prevent tests from using GPUs
        local log_file="${LOG_DIR}/${test_name}_worker${worker_id}.log"

        echo "[$(date '+%Y-%m-%d %H:%M:%S')] [Worker ${worker_id}] Starting: ${test_name}"

        # Run test with CUDA_VISIBLE_DEVICES="" to hide all GPUs from CUDA
        CUDA_VISIBLE_DEVICES="" ${PYTEST} -v -x "${test_file}" > "${log_file}" 2>&1
        local exit_code=$?

        if [ ${exit_code} -eq 0 ]; then
            echo "[$(date '+%Y-%m-%d %H:%M:%S')] [Worker ${worker_id}] ✓ PASSED: ${test_name}"
        else
            echo "[$(date '+%Y-%m-%d %H:%M:%S')] [Worker ${worker_id}] ✗ FAILED: ${test_name} (exit code: ${exit_code})"
        fi
    fi

    return ${exit_code}
}

# Export function and variables for GNU parallel
export -f run_single_test
export PYTEST LOG_DIR NUM_GPUS

# Create joblog file
JOBLOG="${LOG_DIR}/parallel_joblog.txt"

echo "Starting test execution with GNU parallel..."
echo ""

# Run tests in parallel using GNU parallel
# -j WORKERS: run at most WORKERS jobs in parallel
# --halt soon,fail=1: stop as soon as one job fails (like pytest -x)
# --line-buffer: print output line-by-line as it comes
# --joblog: track job execution details
printf '%s\n' "${TEST_FILES[@]}" | parallel \
    -j "${WORKERS}" \
    --halt soon,fail=1 \
    --line-buffer \
    --joblog "${JOBLOG}" \
    run_single_test {}

# Capture parallel's exit code
PARALLEL_EXIT=$?

# Print summary
echo ""
echo "================================================="
echo "Test Summary"
echo "================================================="
echo "Total tests: ${TOTAL_TESTS}"

# Parse joblog to count passed/failed
# Joblog format: Seq Host Starttime JobRuntime Send Receive Exitval Signal Command
# Skip header line, count by exit code
if [ -f "${JOBLOG}" ]; then
    FAILED=$(awk 'NR>1 && $7!=0 {count++} END {print count+0}' "${JOBLOG}")
    PASSED=$((TOTAL_TESTS - FAILED))
else
    # Fallback if joblog doesn't exist
    FAILED=0
    PASSED=${TOTAL_TESTS}
fi

echo "Passed: ${PASSED}"
echo "Failed: ${FAILED}"
echo "================================================="

if [ ${PARALLEL_EXIT} -ne 0 ]; then
    echo ""
    echo "Failed tests:"
    # Extract failed test names from joblog
    awk 'NR>1 && $7!=0 {print $NF}' "${JOBLOG}" | while read test_path; do
        test_name=$(basename "${test_path}" .py)
        echo "  - ${test_name}"
    done
    echo ""
    echo "Check log files in ${LOG_DIR} for details"
    exit 1
else
    echo ""
    echo "All tests passed! ✓"
    exit 0
fi
